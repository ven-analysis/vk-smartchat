{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python2\n",
    "import json\n",
    "from nltk import ngrams\n",
    "import codecs\n",
    "import unicodedata\n",
    "import operator\n",
    "import unicodecsv as csv\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def income_message_processing(message, remove_bot_messages=True):\n",
    "    text = message['text'].encode('utf8')\n",
    "    #import re\n",
    "    #my_str = 'Собеседник:\\nпривет'\n",
    "    #my_mes = re.split('Собеседник:\\n', my_str, maxsplit = 1)[-1].replace('Собеседник отправил стикер','')\n",
    "    #my_str2 = 'Собеседник отправил стикер'\n",
    "    #re.split('Собеседник:\\n', my_str2,)[-1]\n",
    "    \n",
    "    if message['income'] == 1:\n",
    "        #text = text[21:]\n",
    "        text = re.split('Собеседник: ?\\n?', text, maxsplit = 1)[-1]\n",
    "        text = text.replace('Собеседник отправил стикер','')\n",
    "        if remove_bot_messages:\n",
    "            text = text.replace('Бот: Мы заботимся о вашей анонимности и не позволяем пересылать сообщения','')\n",
    "            text = text.replace('Чтобы получить самый интересный опрос, напиши \"опрос\" или \"!\"\\n? ?Чтобы начать анонимный чат, напиши \"чат\"\\n?','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_user_json_to_dict_of_dialog_messages(data, work_type='income'):\n",
    "    \"\"\"data - json, work_type - income only or all messages\"\"\"\n",
    "    work_type_t = 0\n",
    "    if (work_type == 'income'): \n",
    "        work_type_t = 1\n",
    "        \n",
    "    dialogs_ngramms_dict = {}\n",
    "    user_id = data['user_id']\n",
    "    dialogs = data['dialogs']\n",
    "    for d_i, dialog in enumerate(dialogs):\n",
    "        mline = []\n",
    "        for m_i, message in enumerate(dialog):\n",
    "            if message['income'] == work_type_t:\n",
    "                mline.append(income_message_processing(message))\n",
    "        #print d_i, messages_line\n",
    "        messages_line = ''.join(mline)\n",
    "        norm_message = normalise_document(messages_line)\n",
    "        dialogs_ngramms_dict[d_i] = norm_message\n",
    "    return user_id, dialogs_ngramms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_document(doc):\n",
    "    \"\"\"\n",
    "    Convert document to lower-case and remove accents\n",
    "    \n",
    "    Returns:\n",
    "        A normalised document as unicode\n",
    "    \"\"\"\n",
    "    doc = unicode(doc, 'utf-8')\n",
    "    return u''.join(c for c in unicodedata.normalize('NFD', doc.lower()) if not unicodedata.combining(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def message_line_to_ngramm(message_line, n=3):\n",
    "    tokenizer = nltk.WordPunctTokenizer()\n",
    "    for token in tokenizer.tokenize(message_line):\n",
    "        if len(token) >= n:\n",
    "            for ngram in nltk.ngrams(token, n):\n",
    "                yield u\"\".join(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features_by_one_dialog(token_freq, top_tokens=10):\n",
    "    \"\"\"\n",
    "    From each language selects top_tokens to be used as features\n",
    "    Returns:\n",
    "        set(unicode tokens)\n",
    "    \"\"\"\n",
    "    #features = set()\n",
    "    sorted_token_freq = sorted(token_freq.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    #for token, freq in sorted_token_freq[:top_tokens]:\n",
    "    #    features.add(token)\n",
    "    return sorted_token_freq[:top_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_to_features(data):\n",
    "    user_id, dialogs_message_lines = one_user_json_to_dict_of_dialog_messages(data)\n",
    "    dialog_top = {}\n",
    "    for d_i, message_line in dialogs_message_lines.items():\n",
    "        token_freq = {}\n",
    "        for token in message_line_to_ngramm(message_line):\n",
    "            token_freq[token] = 1 + token_freq.get(token, 0) \n",
    "        dialog_top[d_i] = select_features_by_one_dialog(token_freq)\n",
    "    return user_id, dialog_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv(data):\n",
    "    info_list = []\n",
    "    user_id, dialog_top = data_to_features(data)\n",
    "    for d_i, top_tokens in dialog_top.items():\n",
    "        info_list.append([user_id, d_i, json.dumps(top_tokens)])\n",
    "        #print top_tokens\n",
    "    return info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_folder_path = 'json_dialogs'\n",
    "output_folder_path = 'csv_tokens'\n",
    "group_id = 145254340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(join(input_folder_path, '{}.json'.format(group_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile = open(join(output_folder_path, '{}.csv'.format(group_id)), \"wb+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = csv.writer(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.writerow([\"user_id\", \"dialog_number\", \"top_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in f:\n",
    "    data = json.loads(line)\n",
    "    for item in data_to_csv(data):\n",
    "        writer.writerow(item)\n",
    "    #print dialog_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
